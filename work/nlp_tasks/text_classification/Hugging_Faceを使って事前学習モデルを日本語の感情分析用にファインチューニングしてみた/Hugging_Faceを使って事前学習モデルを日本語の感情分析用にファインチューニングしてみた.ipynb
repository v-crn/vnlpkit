{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9303ca1-fa9d-4a35-895c-5f0824d8da3a",
   "metadata": {},
   "source": [
    "# [Hugging Faceを使って事前学習モデルを日本語の感情分析用にファインチューニングしてみた | DevelopersIO](https://dev.classmethod.jp/articles/huggingface-jp-text-classification/)\n",
    "\n",
    "## 必要なライブラリのインストール\n",
    "\n",
    "```\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install fugashi\n",
    "!pip install ipadic\n",
    "```\n",
    "\n",
    "## データセット\n",
    "\n",
    "Hugging Face のデータセット：[Hugging Face – The AI community building the future.](https://huggingface.co/datasets)\n",
    "\n",
    "今回は以下のデータセットのうち、日本語のサブセットを使用します。\n",
    "\n",
    "[tyqiangz/multilingual-sentiments · Datasets at Hugging Face](https://huggingface.co/datasets/tyqiangz/multilingual-sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff25583-9c14-4784-a30d-49a793e01a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<jemalloc>: MADV_DONTNEED does not work (memset will be used instead)\n",
      "<jemalloc>: (This is the expected behaviour if you are running under QEMU)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177c315ab0e24983b1b58b01f745c756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9981a71cbe4fbeb1b988474c83fda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/26.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset multilingual-sentiments/japanese (download: 38.00 MiB, generated: 38.64 MiB, post-processed: Unknown size, total: 76.63 MiB) to /root/.cache/huggingface/datasets/tyqiangz___multilingual-sentiments/japanese/1.0.0/b7cdd8874d82679e59432edf79e074f595c4ad26d2e562eba4fb55f361691b07...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3025882d874ac3863a03aded8c8273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/12.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e8bada998f459588bae0a2d5e1516a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/300k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d90ef62de60447c8dde2576df1e8819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/307k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "                                                text     label  \\\n",
      "0  普段使いとバイクに乗るときのブーツ兼用として購入しました。見た目や履き心地は良いです。 しか...  negative   \n",
      "1  十分な在庫を用意できない販売元も悪いですが、Amazonやら楽⚪︎が転売を認めちゃってるのが...  negative   \n",
      "2  見た目はかなりおしゃれで気に入りました。2、3回持ち歩いた後いつも通りゼンマイを巻いていたら...  negative   \n",
      "3  よくある部分での断線はしませんでした ただiphoneとの接続部で接触不良、折れました ip...  negative   \n",
      "4  プラモデルの塗装剥離に使う為に購入 届いて早速使ってみた 結果 １ヶ月経っても未だに剥離出来...  negative   \n",
      "\n",
      "                 source  \n",
      "0  amazon_reviews_multi  \n",
      "1  amazon_reviews_multi  \n",
      "2  amazon_reviews_multi  \n",
      "3  amazon_reviews_multi  \n",
      "4  amazon_reviews_multi  \n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "                                                text     label  \\\n",
      "0  味自体及び吸い心地は良いのだが、不良品が多過ぎる。私の場合５本のうち２本が蒸気も出ず、吸い込...  negative   \n",
      "1             ホームボタン周りの気泡が全く抜けません。 返金をお願いしましたが、断られた。  negative   \n",
      "2  新旧含めて4つのカーテンレールがあるのですが、使用出来るカーテンレールはありませんでした。 ...  negative   \n",
      "3            予約注文でしたが、どこから特典であるpdfダウンロードすればよいのでしょうか…  negative   \n",
      "4  前のレビューにもありましたが、片方が全く動きません。 返品しようにも、なんだかめんどくさいし...  negative   \n",
      "\n",
      "                 source  \n",
      "0  amazon_reviews_multi  \n",
      "1  amazon_reviews_multi  \n",
      "2  amazon_reviews_multi  \n",
      "3  amazon_reviews_multi  \n",
      "4  amazon_reviews_multi  \n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "                                                text     label  \\\n",
      "0  購入、貼付け後2週間もたたないうちに、上側から剥がれてきて画面から浮いた状態になってしまった...  negative   \n",
      "1  以下の3点の理由により、期待はずれの粗悪品。 ①他の方のレビューにもある通り、天板の外観が掲...  negative   \n",
      "2  この商品の内容等確認した購入したのですが、そのとおりなかなか設定ができなく、知人にもお願いし...  negative   \n",
      "3  テストした結果、4000mahのスマホ一回と30％分、スマホのバッテリー残量の表示が正しけれ...  negative   \n",
      "4  前回の黒いドレッサーバッグの評判がよかったため、予約して購入しました。 ガッカリです。 ヨレ...  negative   \n",
      "\n",
      "                 source  \n",
      "0  amazon_reviews_multi  \n",
      "1  amazon_reviews_multi  \n",
      "2  amazon_reviews_multi  \n",
      "3  amazon_reviews_multi  \n",
      "4  amazon_reviews_multi  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Dataset multilingual-sentiments downloaded and prepared to /root/.cache/huggingface/datasets/tyqiangz___multilingual-sentiments/japanese/1.0.0/b7cdd8874d82679e59432edf79e074f595c4ad26d2e562eba4fb55f361691b07. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f40a61efa0443118f9e75cbf4630638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"tyqiangz/multilingual-sentiments\", \"japanese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43932450-9c8b-4a80-a615-b12cb8249347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'source', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'source', 'label'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'source', 'label'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bab7dc-af11-41ec-b637-87ad5400c08f",
   "metadata": {},
   "source": [
    "取得したデータセットは以下のようにフォーマットを設定することで、データフレームとして扱うことも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec5d53d-1687-40d3-982f-c0d5f5f3ba11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>普段使いとバイクに乗るときのブーツ兼用として購入しました。見た目や履き心地は良いです。 しか...</td>\n",
       "      <td>amazon_reviews_multi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>十分な在庫を用意できない販売元も悪いですが、Amazonやら楽⚪︎が転売を認めちゃってるのが...</td>\n",
       "      <td>amazon_reviews_multi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>見た目はかなりおしゃれで気に入りました。2、3回持ち歩いた後いつも通りゼンマイを巻いていたら...</td>\n",
       "      <td>amazon_reviews_multi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>よくある部分での断線はしませんでした ただiphoneとの接続部で接触不良、折れました ip...</td>\n",
       "      <td>amazon_reviews_multi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>プラモデルの塗装剥離に使う為に購入 届いて早速使ってみた 結果 １ヶ月経っても未だに剥離出来...</td>\n",
       "      <td>amazon_reviews_multi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                source  \\\n",
       "0  普段使いとバイクに乗るときのブーツ兼用として購入しました。見た目や履き心地は良いです。 しか...  amazon_reviews_multi   \n",
       "1  十分な在庫を用意できない販売元も悪いですが、Amazonやら楽⚪︎が転売を認めちゃってるのが...  amazon_reviews_multi   \n",
       "2  見た目はかなりおしゃれで気に入りました。2、3回持ち歩いた後いつも通りゼンマイを巻いていたら...  amazon_reviews_multi   \n",
       "3  よくある部分での断線はしませんでした ただiphoneとの接続部で接触不良、折れました ip...  amazon_reviews_multi   \n",
       "4  プラモデルの塗装剥離に使う為に購入 届いて早速使ってみた 結果 １ヶ月経っても未だに剥離出来...  amazon_reviews_multi   \n",
       "\n",
       "   label  \n",
       "0      2  \n",
       "1      2  \n",
       "2      2  \n",
       "3      2  \n",
       "4      2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.set_format(type=\"pandas\")\n",
    "train_df = dataset[\"train\"][:]\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9760c043-a23c-4397-be55-59e06d007b14",
   "metadata": {},
   "source": [
    "どうやらamazonのレビューデータが元になって、そちらに対してラベルが付与されているようです。\n",
    "\n",
    "`source` と `label` の内訳を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ef5eb4-8868-4154-bf47-1469d9fe480a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source                label\n",
       "amazon_reviews_multi  0        40000\n",
       "                      1        40000\n",
       "                      2        40000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.value_counts([\"source\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b09a1f-8c2d-48dd-a921-f1c699cf2d2e",
   "metadata": {},
   "source": [
    "各ラベルの意味については、featuresを見れば分かるようになっています。\n",
    "\n",
    "featuresは、各列の値についての詳細が記載してあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed6702f5-d39d-4391-b2f2-44927ef25e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'source': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(num_classes=3, names=['positive', 'neutral', 'negative'], id=None)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ca56db-a5c9-46a7-a083-eadefb653061",
   "metadata": {},
   "source": [
    "このように、labelはClassLabelクラスとなっており、0,1,2がそれぞれ'positive','neutral','negative'に割り当てられていることが分かります。\n",
    "\n",
    "ClassLabelクラスには、int2strというメソッドがあり、これでラベル名に変換することが可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e16840a8-35b3-42a6-84b6-a52aabb1983b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbba986fcaac4b4f846ca8f74dd4ac41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>普段使いとバイクに乗るときのブーツ兼用として購入しました。見た目や履き心地は良いです。 しか...</td>\n",
       "      <td>amazon_reviews_multi</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>十分な在庫を用意できない販売元も悪いですが、Amazonやら楽⚪︎が転売を認めちゃってるのが...</td>\n",
       "      <td>amazon_reviews_multi</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>見た目はかなりおしゃれで気に入りました。2、3回持ち歩いた後いつも通りゼンマイを巻いていたら...</td>\n",
       "      <td>amazon_reviews_multi</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>よくある部分での断線はしませんでした ただiphoneとの接続部で接触不良、折れました ip...</td>\n",
       "      <td>amazon_reviews_multi</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>プラモデルの塗装剥離に使う為に購入 届いて早速使ってみた 結果 １ヶ月経っても未だに剥離出来...</td>\n",
       "      <td>amazon_reviews_multi</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                source  \\\n",
       "0  普段使いとバイクに乗るときのブーツ兼用として購入しました。見た目や履き心地は良いです。 しか...  amazon_reviews_multi   \n",
       "1  十分な在庫を用意できない販売元も悪いですが、Amazonやら楽⚪︎が転売を認めちゃってるのが...  amazon_reviews_multi   \n",
       "2  見た目はかなりおしゃれで気に入りました。2、3回持ち歩いた後いつも通りゼンマイを巻いていたら...  amazon_reviews_multi   \n",
       "3  よくある部分での断線はしませんでした ただiphoneとの接続部で接触不良、折れました ip...  amazon_reviews_multi   \n",
       "4  プラモデルの塗装剥離に使う為に購入 届いて早速使ってみた 結果 １ヶ月経っても未だに剥離出来...  amazon_reviews_multi   \n",
       "\n",
       "   label label_name  \n",
       "0      2   negative  \n",
       "1      2   negative  \n",
       "2      2   negative  \n",
       "3      2   negative  \n",
       "4      2   negative  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "def label_int2str(x):\n",
    "    return dataset[\"train\"].features[\"label\"].int2str(x)\n",
    "\n",
    "\n",
    "# train_df[\"label_name\"] = train_df[\"label\"].apply(label_int2str)\n",
    "\n",
    "\n",
    "def _func(x, pbar) -> list[str]:\n",
    "    result = label_int2str(int(x))\n",
    "    pbar.update(1)\n",
    "    return result\n",
    "\n",
    "\n",
    "input_data = train_df[\"label\"]\n",
    "\n",
    "with tqdm(total=len(input_data)) as pbar:\n",
    "    train_df[\"label_name\"] = np.vectorize(_func)(input_data, pbar)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f5a049-92c7-443d-a868-884e3cef560a",
   "metadata": {},
   "source": [
    "最後に、データフレームにしていたフォーマットを元に戻しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "976af1c1-3ae3-45c0-b70e-6f45f994a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab22fc0-d3f9-438d-8196-a303d062c651",
   "metadata": {},
   "source": [
    "## モデルの検索\n",
    "\n",
    "データをトークナイザで処理する前に、使用する事前学習モデルを決める必要があります。理由としては、通常事前学習モデルを作成した時と同じトークナイザを使用する必要があるためと考えられます。\n",
    "\n",
    "モデルの検索もHugging Faceのページに準備されており、以下から検索が可能です。\n",
    "\n",
    "<https://huggingface.co/models>\n",
    "\n",
    "この中で、BERTの日本語版を探し、その中が比較的ダウンロード数の多い以下を使用することにします。\n",
    "\n",
    "<https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking>\n",
    "\n",
    "他にも様々な事前学習モデルがありますが、後述するトークナイザの精度などを確認し、問題が無さそうなものを選択しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d9247c-a239-4b37-bad4-ba9709dd46b0",
   "metadata": {},
   "source": [
    "## トークナイザの動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10d9d0b2-174b-4b08-b759-e485fd021fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d42042f636464eb7a5a99b365bdae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/110 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde09587ca744a8c94df9f994799f697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/479 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38289145294b4918b1a4888c7f9d6eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/258k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_ckpt = \"cl-tohoku/bert-base-japanese-whole-word-masking\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efb8741f-97d3-4804-9566-bc862c9ccd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\\\n",
    "機械学習のコア部分のロジックを、定型的な実装部分から切り離して\\\n",
    "定義できるようなインターフェースに工夫されています。 \\\n",
    "そのためユーザーは、機械学習のコア部分のロジックの検討に\\\n",
    "集中することができます。\\\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9fac040-3020-4e72-b414-c545f0b7cf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 2943, 4293, 5, 6759, 972, 5, 138, 17394, 11, 6, 23398, 81, 18, 6561, 972, 40, 24547, 16, 2279, 392, 124, 18, 23953, 7, 9909, 26, 20, 16, 21, 2610, 8, 59, 82, 4502, 9, 6, 2943, 4293, 5, 6759, 972, 5, 138, 17394, 5, 3249, 7, 4155, 34, 45, 14, 203, 2610, 8, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "sample_text_encoded = tokenizer(sample_text)\n",
    "print(sample_text_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9333dd-ad09-4f08-9e0c-da00e8e3d0b8",
   "metadata": {},
   "source": [
    "結果はこのように、`input_ids` と `attention_mask` が含まれます。\n",
    "\n",
    "input_idsは数字にエンコードされたトークンで、`attention_mask` は後段のモデルで有効なトークンかどうかを判別するためのマスクです。\n",
    "\n",
    "無効なトークン（例えば、`[PAD]` など）に対しては、`attention_mask` を 0 として処理します。\n",
    "\n",
    "トークナイザの結果は数字にエンコードされているため、トークン文字列を得るには、`convert_ids_to_tokens` を用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b870af5e-af0a-4350-aea3-382e2c756e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '機械', '学習', 'の', 'コア', '部分', 'の', 'ロ', '##ジック', 'を', '、', '定型', '的', 'な', '実装', '部分', 'から', '切り離し', 'て', '定義', 'できる', 'よう', 'な', 'インターフェース', 'に', '工夫', 'さ', 'れ', 'て', 'い', 'ます', '。', 'その', 'ため', 'ユーザー', 'は', '、', '機械', '学習', 'の', 'コア', '部分', 'の', 'ロ', '##ジック', 'の', '検討', 'に', '集中', 'する', 'こと', 'が', 'でき', 'ます', '。', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(sample_text_encoded.input_ids)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840d6109-cbe8-4283-ba7a-7610a8eac7d4",
   "metadata": {},
   "source": [
    "結果がこのように得られます。\n",
    "\n",
    "先頭に##が付加されているものは、サブワード分割されているものです。\n",
    "\n",
    "また、系列の開始が[CLS]、系列の終了(実際は複数系列の切れ目)が[SEP]という特殊なトークンとなっています。\n",
    "\n",
    "トークナイザについては以下にも説明があります。\n",
    "\n",
    "[cl-tohoku/bert-base-japanese-whole-word-masking · Hugging Face](https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking)\n",
    "\n",
    "> The texts are first tokenized by MeCab morphological parser with the IPA dictionary and then split into subwords by the WordPiece algorithm. The vocabulary size is 32000.\n",
    "\n",
    "トークン化にIPA辞書を使ったMecabが使用され、サブワード分割にはWordPieceアルゴリズムが使われているようです。\n",
    "\n",
    "その他、文字列を再構成するには、convert_tokens_to_stringを用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f42ff71a-08a3-4883-8a10-3b0ed66f63e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 機械 学習 の コア 部分 の ロジック を 、 定型 的 な 実装 部分 から 切り離し て 定義 できる よう な インターフェース に 工夫 さ れ て い ます 。 その ため ユーザー は 、 機械 学習 の コア 部分 の ロジック の 検討 に 集中 する こと が でき ます 。 [SEP]\n"
     ]
    }
   ],
   "source": [
    "decode_text = tokenizer.convert_tokens_to_string(tokens)\n",
    "print(decode_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4705b83-5a16-46a9-a5d9-a9c01469f5ef",
   "metadata": {},
   "source": [
    "## データセット全体のトークン化\n",
    "\n",
    "データセット全体に処理を適用するには、バッチ単位で処理する関数を定義し、mapを使って実施します。\n",
    "\n",
    "- `padding=True` でバッチ内の最も長い系列長に合うようpaddingする処理を有効にします。\n",
    "- `truncation=True` で、後段のモデルが対応する最大コンテキストサイズ以上を切り捨てます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76b912e4-3341-4fb1-a3e9-0d423b88746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2a0966-bf82-440f-bb89-a4278e5059c2",
   "metadata": {},
   "source": [
    "参考までにモデルが対応する最大コンテキストサイズは、以下で確認ができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2db64115-d6f3-42c3-b119-c5fd470fc98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4da881-6097-4627-9bc3-75d8db4e2cb5",
   "metadata": {},
   "source": [
    "これをデータセット全体に適用します。\n",
    "\n",
    "- `batched=True` によりバッチ化され、`batch_size=None` により全体が1バッチとなります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a5fb0de-4f2a-426c-8b63-5003565bdac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026fc7f98daa41dd82d26bca9d71655e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b51c27d36c045e0a4f066207d39eee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6437d99efd42e8b0be78d8df1b2ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "dataset_encoded = dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "188e1475-e611-411f-affc-e1a4b80d778e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'source', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'source', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'source', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e25c45-9d24-4255-be41-512a4977e999",
   "metadata": {},
   "source": [
    "データセット全体に適用され、カラムが追加されていることが分かります。\n",
    "\n",
    "token_types_idは今回使用しませんが、複数の系列がある場合に使用されます。(詳細は下記を参照)\n",
    "\n",
    "[Glossary](https://huggingface.co/docs/transformers/glossary#token-type-ids)\n",
    "\n",
    "サンプル単位で結果を確認したい場合は、データフレームなどを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eeaf266e-b3d2-41bb-8975-4b0707f5d50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9406</td>\n",
       "      <td>1</td>\n",
       "      <td>普段</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3276</td>\n",
       "      <td>1</td>\n",
       "      <td>使い</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>と</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10602</td>\n",
       "      <td>1</td>\n",
       "      <td>バイク</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[PAD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[PAD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[PAD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[PAD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[PAD]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_ids attention_mask tokens\n",
       "0           2              1  [CLS]\n",
       "1        9406              1     普段\n",
       "2        3276              1     使い\n",
       "3          13              1      と\n",
       "4       10602              1    バイク\n",
       "..        ...            ...    ...\n",
       "507         0              0  [PAD]\n",
       "508         0              0  [PAD]\n",
       "509         0              0  [PAD]\n",
       "510         0              0  [PAD]\n",
       "511         0              0  [PAD]\n",
       "\n",
       "[512 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample_encoded = dataset_encoded[\"train\"][0]\n",
    "pd.DataFrame(\n",
    "    [\n",
    "        sample_encoded[\"input_ids\"],\n",
    "        sample_encoded[\"attention_mask\"],\n",
    "        tokenizer.convert_ids_to_tokens(sample_encoded[\"input_ids\"]),\n",
    "    ],\n",
    "    [\"input_ids\", \"attention_mask\", \"tokens\"],\n",
    ").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39e4745-7801-47b5-9071-9e37221a53e6",
   "metadata": {},
   "source": [
    "## 分類器の実現方法\n",
    "\n",
    "テキスト分類のためにはここから、BERTモデルの後段に分類用のヘッドを接続する必要があります。\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/cm-nakamura-shogo/devio-image/main/huggingface-jp-text-classification/huggingface-jp-text-classification-2.png\" alt=\"drawing\" width=\"200\"/>\n",
    "\n",
    "接続後、テキスト分類を学習する方法に大きく２種類あります。\n",
    "\n",
    "接続した分類用ヘッドのみを学習\n",
    "BERTを含むモデル全体を学習(fine-tuning)\n",
    "前者は高速な学習が可能でGPUなどが利用できない場合に選択肢になり、後者の方がよりタスクに特化できるので高精度となります。\n",
    "\n",
    "本記事では後者のfine-tuningする方法で実装していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470188ea-a344-4469-a53c-aee1b846991e",
   "metadata": {},
   "source": [
    "## 分類器の実装\n",
    "\n",
    "今回のようなテキストを系列単位で分類するタスクには、既にそれ専用のクラスが準備されており、以下で構築が可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f71c0fe-dc44-4007-b5c3-408d70401197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983035d0cf194ea9b4973c30784020d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_labels = 3\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_ckpt, num_labels=num_labels\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf7189a-415f-4765-bd60-f5989a4b3ff0",
   "metadata": {},
   "source": [
    "## トレーニングの準備\n",
    "\n",
    "学習時に性能指標を与える必要があるため、それを関数化して定義しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ace9be31-0448-4136-977d-4d34c04adf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b3ad2b-9f6f-4df4-8339-f491109b288a",
   "metadata": {},
   "source": [
    "こちらは `EvalPrediction` オブジェクトをうけとる形で実装します。\n",
    "\n",
    "`EvalPrediciton` オブジェクトは、`predictions` と `label_ids` という属性を持つ `named_tuple` です。\n",
    "\n",
    "そして学習用のパラメータを `TrainingArguments` クラスを用いて設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef0f8d8e-74f7-4cd5-8c88-9abbb999fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 16\n",
    "logging_steps = len(dataset_encoded[\"train\"]) // batch_size\n",
    "model_name = \"sample-text-classification-bert\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=False,\n",
    "    log_level=\"error\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594a1a03-3f3a-4587-84c4-dc482044532e",
   "metadata": {},
   "source": [
    "## トレーニングの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f665e6-bfc1-44fc-9959-facd6785e1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset_encoded[\"train\"],\n",
    "    eval_dataset=dataset_encoded[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314405f6-e711-4a1a-bd4e-308d3e9b2bd4",
   "metadata": {},
   "source": [
    "## 推論テスト\n",
    "\n",
    "推論結果は `predict` により得ることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c41d5d-5d50-4b74-ae85-5f29a7da856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_output = trainer.predict(dataset_encoded[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e08d273-4a90-4371-810b-0800a47b2e23",
   "metadata": {},
   "source": [
    "これを混同行列で可視化してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c2dde3-9899-4053-a730-8314f5a86e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "y_preds = np.argmax(preds_output.predictions, axis=1)\n",
    "y_valid = np.array(dataset_encoded[\"validation\"][\"label\"])\n",
    "labels = dataset_encoded[\"train\"].features[\"label\"].names\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_confusion_matrix(y_preds, y_valid, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18d5693-bf8a-4e05-9eb5-68bc720425a0",
   "metadata": {},
   "source": [
    "positive, negativeについては9割以上で正解できていますが、neutralの判別が少し難しくなっていそうです。\n",
    "またpositiveをnegativeに間違えたり、negativeをpositiveに間違えたりすることは少ないようです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e9873-a738-4603-9725-7c368188ec18",
   "metadata": {},
   "source": [
    "## モデル保存\n",
    "\n",
    "保存前にラベル情報を設定しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4aa6cc-cf86-4fe1-836b-a6b0292120b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {}\n",
    "for i in range(dataset[\"train\"].features[\"label\"].num_classes):\n",
    "    id2label[i] = dataset[\"train\"].features[\"label\"].int2str(i)\n",
    "\n",
    "label2id = {}\n",
    "for i in range(dataset[\"train\"].features[\"label\"].num_classes):\n",
    "    label2id[dataset[\"train\"].features[\"label\"].int2str(i)] = i\n",
    "\n",
    "trainer.model.config.id2label = id2label\n",
    "trainer.model.config.label2id = label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5847df5d-c08f-4342-8f99-b775a3ba411d",
   "metadata": {},
   "source": [
    "`save_model` で保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d1112-726c-4126-a163-4180895c9958",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"work/nlp_tasks/text_classification/Hugging_Faceを使って事前学習モデルを日本語の感情分析用にファインチューニングしてみた/sample-text-classification-bert\"\n",
    "trainer.save_model(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d76f0f-44c9-43ed-823f-ab32340b184c",
   "metadata": {},
   "source": [
    "保存結果は以下のようなファイル構成となります。\n",
    "\n",
    "```txt\n",
    "sample-text-classification-bert\n",
    "├── config.json\n",
    "├── pytorch_model.bin\n",
    "├── special_tokens_map.json\n",
    "├── tokenizer_config.json\n",
    "├── training_args.bin\n",
    "└── vocab.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acb6dc3-01e2-40dc-a73b-59117234b16e",
   "metadata": {},
   "source": [
    "モデルやトークナイザの設定ファイル、そしてメインのモデルは pytorch_model.bin として保存されているようです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988f0735-5268-48e3-854d-5165c26de733",
   "metadata": {},
   "source": [
    "## ロードして推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b426b-4b6c-48b1-896f-176e5e2fe3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "new_model = AutoModelForSequenceClassification.from_pretrained(model_dir).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b5c9b-d6cd-48f5-9d2e-ace1329ea6d8",
   "metadata": {},
   "source": [
    "サンプルテキストを推論します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e944c102-2a5e-4106-9444-bc5e6f3f1ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = new_tokenizer(sample_text, return_tensors=\"pt\")\n",
    "\n",
    "new_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = new_model(\n",
    "        inputs[\"input_ids\"].to(device),\n",
    "        inputs[\"attention_mask\"].to(device),\n",
    "    )\n",
    "outputs.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d65581-9d28-4fec-91a8-582da70e48f7",
   "metadata": {},
   "source": [
    "logitsを推論ラベルに変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54da2fa-42f1-4c49-823c-8b854e8e9d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.argmax(outputs.logits.to(\"cpu\").detach().numpy().copy(), axis=1)\n",
    "\n",
    "\n",
    "def id2label(x):\n",
    "    return new_model.config.id2label[x]\n",
    "\n",
    "\n",
    "y_dash = [id2label(x) for x in y_preds]\n",
    "y_dash"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
